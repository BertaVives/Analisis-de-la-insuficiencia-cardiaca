{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos los datos a un DataFrame\n",
    "file = '../data/heart_failure_clinical_records_dataset.csv'\n",
    "data = pd.read_csv(file, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_names = ['weibull_min','norm','weibull_max','beta',\n",
    "             'invgauss','uniform','gamma','expon',   \n",
    "              'lognorm','pearson3','triang']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "len() of unsized object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mfor\u001b[39;00m distribution \u001b[39min\u001b[39;00m dist_names:\n\u001b[1;32m     14\u001b[0m     \u001b[39m# Set up distribution and get fitted distribution parameters\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     dist \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(scipy\u001b[39m.\u001b[39mstats, distribution)\n\u001b[0;32m---> 16\u001b[0m     param \u001b[39m=\u001b[39m dist\u001b[39m.\u001b[39;49mfit(y_std)\n\u001b[1;32m     17\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(dist, param))\n\u001b[1;32m     20\u001b[0m     \u001b[39m# Get expected counts in percentile bins\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     \u001b[39m# cdf of fitted sistrinution across bins\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/DataScience/lib/python3.9/site-packages/scipy/stats/_distn_infrastructure.py:2672\u001b[0m, in \u001b[0;36mrv_continuous.fit\u001b[0;34m(self, data, *args, **kwds)\u001b[0m\n\u001b[1;32m   2667\u001b[0m \u001b[39m# In some cases, method of moments can be done with fsolve/root\u001b[39;00m\n\u001b[1;32m   2668\u001b[0m \u001b[39m# instead of an optimizer, but sometimes no solution exists,\u001b[39;00m\n\u001b[1;32m   2669\u001b[0m \u001b[39m# especially when the user fixes parameters. Minimizing the sum\u001b[39;00m\n\u001b[1;32m   2670\u001b[0m \u001b[39m# of squares of the error generalizes to these cases.\u001b[39;00m\n\u001b[1;32m   2671\u001b[0m vals \u001b[39m=\u001b[39m optimizer(func, x0, args\u001b[39m=\u001b[39m(ravel(data),), disp\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m-> 2672\u001b[0m obj \u001b[39m=\u001b[39m func(vals, data)\n\u001b[1;32m   2674\u001b[0m \u001b[39mif\u001b[39;00m restore \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2675\u001b[0m     vals \u001b[39m=\u001b[39m restore(args, vals)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/DataScience/lib/python3.9/site-packages/scipy/stats/_distn_infrastructure.py:1653\u001b[0m, in \u001b[0;36mrv_generic._penalized_nnlf\u001b[0;34m(self, theta, x)\u001b[0m\n\u001b[1;32m   1651\u001b[0m     \u001b[39mreturn\u001b[39;00m inf\n\u001b[1;32m   1652\u001b[0m x \u001b[39m=\u001b[39m asarray((x\u001b[39m-\u001b[39mloc) \u001b[39m/\u001b[39m scale)\n\u001b[0;32m-> 1653\u001b[0m n_log_scale \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39;49m(x) \u001b[39m*\u001b[39m log(scale)\n\u001b[1;32m   1654\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_nnlf_and_penalty(x, args) \u001b[39m+\u001b[39m n_log_scale\n",
      "\u001b[0;31mTypeError\u001b[0m: len() of unsized object"
     ]
    }
   ],
   "source": [
    "y_std = np.std(data['ejection_fraction'])\n",
    "size = len(data['ejection_fraction'])\n",
    "\n",
    "chi_square_statistics = []\n",
    "\n",
    "# 11 equi-distant bins of observed Data \n",
    "percentile_bins = np.linspace(0,100,11)\n",
    "percentile_cutoffs = np.percentile(y_std, percentile_bins)\n",
    "observed_frequency, bins = (np.histogram(y_std, bins=percentile_cutoffs))\n",
    "cum_observed_frequency = np.cumsum(observed_frequency)\n",
    "\n",
    "# Loop through candidate distributions\n",
    "for distribution in dist_names:\n",
    "    # Set up distribution and get fitted distribution parameters\n",
    "    dist = getattr(scipy.stats, distribution)\n",
    "    param = dist.fit(y_std)\n",
    "    print(\"{}\\n{}\\n\".format(dist, param))\n",
    "\n",
    "\n",
    "    # Get expected counts in percentile bins\n",
    "    # cdf of fitted sistrinution across bins\n",
    "    cdf_fitted = dist.cdf(percentile_cutoffs, *param)\n",
    "    expected_frequency = []\n",
    "    for bin in range(len(percentile_bins)-1):\n",
    "        expected_cdf_area = cdf_fitted[bin+1] - cdf_fitted[bin]\n",
    "        expected_frequency.append(expected_cdf_area)\n",
    "\n",
    "    # Chi-square Statistics\n",
    "    expected_frequency = np.array(expected_frequency) * size\n",
    "    cum_expected_frequency = np.cumsum(expected_frequency)\n",
    "    ss = sum (((cum_expected_frequency - cum_observed_frequency) ** 2) / cum_observed_frequency)\n",
    "    chi_square_statistics.append(ss)\n",
    "\n",
    "\n",
    "#Sort by minimum ch-square statistics\n",
    "results = pd.DataFrame()\n",
    "results['Distribution'] = dist_names\n",
    "results['chi_square'] = chi_square_statistics\n",
    "results.sort_values(['chi_square'], inplace=True)\n",
    "\n",
    "\n",
    "print ('\\nDistributions listed by Betterment of fit:')\n",
    "print ('............................................')\n",
    "print (results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b5a2aaf94a20ece0551648939ed853b4738d2f77c0cac11f174cba8f59e450c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
